{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy of Mising-Sentence -RU 05.02.ipynb","provenance":[{"file_id":"1293VTRJEbFxjihJcsR8LH107rUhXrN1L","timestamp":1612575651347},{"file_id":"1mLMStw7g79adSzX0PLLYiYPw9SvW5XM3","timestamp":1612519922639},{"file_id":"1fIlkLC6Nk-O2e3SVpbKT3J6gyGnkJA5T","timestamp":1612356026524},{"file_id":"1Z8w7FwaHclb3SvpZ49vqy7Oox19052mk","timestamp":1612189409888},{"file_id":"1kB4aPTsUf5DiKQscY2usDM_je-XaBikc","timestamp":1610235024933}],"collapsed_sections":["CWPGQx-ikMc8","9cfF9Wz9etUn"],"toc_visible":true,"machine_shape":"hm","mount_file_id":"1KGXZ6_jGMLAwS5lI1tOD5i0jiHuUQ4rD","authorship_tag":"ABX9TyPM82d+ti4OzFKiF04lDxR5"},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8d912b0ed7db4fecb93e6fa986f69975":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1685947baaf04e799d6fc40b3be3e545","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e49bfb4d143e4707bbac41eed4fa8022","IPY_MODEL_49f5180d1e5247a8b28afa5d3c82ea9a"]}},"1685947baaf04e799d6fc40b3be3e545":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e49bfb4d143e4707bbac41eed4fa8022":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0de803f71b5a43129d65271c12704fb2","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":642,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":642,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0b384e76c6e749fe8e72df8c557a56a9"}},"49f5180d1e5247a8b28afa5d3c82ea9a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dd47a499700145849c9894498ae95182","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 642/642 [00:00&lt;00:00, 1.05kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6d445b8a18744e02959b820658351fb2"}},"0de803f71b5a43129d65271c12704fb2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0b384e76c6e749fe8e72df8c557a56a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dd47a499700145849c9894498ae95182":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6d445b8a18744e02959b820658351fb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c1f3e10975114d58b8417114371af6d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5e9b1ed3c530486a901880495d4d4b54","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2006e8a2a935484eb897fbad08134e63","IPY_MODEL_e84fb36309a64db5a5971ec1485a41f6"]}},"5e9b1ed3c530486a901880495d4d4b54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2006e8a2a935484eb897fbad08134e63":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c40fee287bf34269bd1dd96fcb0079cc","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1649718,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1649718,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0245b63b9fc0458d96f0274ecc9ead7f"}},"e84fb36309a64db5a5971ec1485a41f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_13290f90835d43e6a2bfcfe3087846b7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.65M/1.65M [00:00&lt;00:00, 3.80MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_51118a83882d4db3ae9fb25afff5bd8f"}},"c40fee287bf34269bd1dd96fcb0079cc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0245b63b9fc0458d96f0274ecc9ead7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"13290f90835d43e6a2bfcfe3087846b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"51118a83882d4db3ae9fb25afff5bd8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9dc5b5456e524e4dbf06023429fb9104":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2c5bdfcacf38484e9de3f3fe69c0189b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f9f045480bf04bf8b438116ad1843536","IPY_MODEL_31b4ed55ec3849cbb66e98a2d97b500d"]}},"2c5bdfcacf38484e9de3f3fe69c0189b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f9f045480bf04bf8b438116ad1843536":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c80494ec9c78497b81da2535c6109ee5","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":112,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":112,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_14d4fd2e75454e2bbdd9edf850624d2d"}},"31b4ed55ec3849cbb66e98a2d97b500d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8b1bed71822c4cd19a18bebcc654608b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 112/112 [00:00&lt;00:00, 1.14kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_04308c67dbd74d008ee5ec9153b91c93"}},"c80494ec9c78497b81da2535c6109ee5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"14d4fd2e75454e2bbdd9edf850624d2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8b1bed71822c4cd19a18bebcc654608b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"04308c67dbd74d008ee5ec9153b91c93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d44a1e8a69ae4c7cbeb0349e5857c901":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7a761fdf585e4a69b276fbfc42af68e6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e83c0a5005274b5893a5c57bcaca9aa1","IPY_MODEL_526e63eb13eb48b99d7e4a1db12c47c7"]}},"7a761fdf585e4a69b276fbfc42af68e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e83c0a5005274b5893a5c57bcaca9aa1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_dd853ba61682432b8ec06d9923922565","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b1ad643b83ac49159282de271dc653f0"}},"526e63eb13eb48b99d7e4a1db12c47c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_14d2f248b3b04fb7a05cfc27238a7d07","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.00/2.00 [00:00&lt;00:00, 7.79B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_50c4430b84394efba997930a7022e4fb"}},"dd853ba61682432b8ec06d9923922565":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b1ad643b83ac49159282de271dc653f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"14d2f248b3b04fb7a05cfc27238a7d07":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"50c4430b84394efba997930a7022e4fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9af858736e57436c8bf00b4061b000a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_71375a55e46f43b9b697e6cbcb9f32d9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6695e654996844fc926d57125402324b","IPY_MODEL_dc1b5060000248f785ddeb5ccee12b26"]}},"71375a55e46f43b9b697e6cbcb9f32d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6695e654996844fc926d57125402324b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4dce73f5d53b4d3091aec693ce6a0f4e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":711456796,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":711456796,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9099753ede814d50a8ad2b4c7b20c8ed"}},"dc1b5060000248f785ddeb5ccee12b26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_88412f9281784227ad75a124bd1347da","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 711M/711M [00:09&lt;00:00, 72.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f1220a3a788c4828979879bcc14216a5"}},"4dce73f5d53b4d3091aec693ce6a0f4e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9099753ede814d50a8ad2b4c7b20c8ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"88412f9281784227ad75a124bd1347da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f1220a3a788c4828979879bcc14216a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c4237b8a2df24a99af284c5bd5af528a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3b07d7fdfd3a4cc9ae8c6d1510e122ed","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c02839a1422f4cf69869d08ee617af0e","IPY_MODEL_a4bef0b1efb1434486b34cebbcd03a99"]}},"3b07d7fdfd3a4cc9ae8c6d1510e122ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c02839a1422f4cf69869d08ee617af0e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6bc9c85af621442490f63415d39239b5","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b4dea257100c4c08a6cae232e2052dd9"}},"a4bef0b1efb1434486b34cebbcd03a99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e09b7f1ac3b54a328535fe877ee30e7d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:00&lt;00:00, 1.08kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d278dab3ff6f4084960cb28ff4b20361"}},"6bc9c85af621442490f63415d39239b5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b4dea257100c4c08a6cae232e2052dd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e09b7f1ac3b54a328535fe877ee30e7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d278dab3ff6f4084960cb28ff4b20361":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8fd73873285b4f2982cf94a73bb88181":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_34cef223c90246acafd0aab2ac3206d2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_15b710c8ba4a4984bf3d7225db28a2d5","IPY_MODEL_4a57c1a658f047399994c9909e5b487c"]}},"34cef223c90246acafd0aab2ac3206d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"15b710c8ba4a4984bf3d7225db28a2d5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ab7159d6db0a4fd1b1f725f6da5ccd37","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":995526,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":995526,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f5f6fe10a3fd4f3288c2d1fe9e8aa2bd"}},"4a57c1a658f047399994c9909e5b487c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_52f3dea741d44d8a91fabd21a9af3bfd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 996k/996k [00:00&lt;00:00, 1.67MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0dbd2f2d34d64e5ea1f9d329f2d9226e"}},"ab7159d6db0a4fd1b1f725f6da5ccd37":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f5f6fe10a3fd4f3288c2d1fe9e8aa2bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"52f3dea741d44d8a91fabd21a9af3bfd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0dbd2f2d34d64e5ea1f9d329f2d9226e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eae0d830d0c541b08cce2d7826575c23":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6d61c5544cd74621bd12e65d76f90194","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_02f1afb1690d45ba8733ef1e4888157c","IPY_MODEL_be89845856b7438ba7ddbda16f90edff"]}},"6d61c5544cd74621bd12e65d76f90194":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"02f1afb1690d45ba8733ef1e4888157c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c1469f81563341e890e7b688916c6ce8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":714314041,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":714314041,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4a88e873914d419883105c6065d72ae5"}},"be89845856b7438ba7ddbda16f90edff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dc4331a83267411d9da13b94de9ecce0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 714M/714M [00:08&lt;00:00, 82.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f0d7db45eeaf461f89439b873c03619b"}},"c1469f81563341e890e7b688916c6ce8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4a88e873914d419883105c6065d72ae5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dc4331a83267411d9da13b94de9ecce0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f0d7db45eeaf461f89439b873c03619b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"CWPGQx-ikMc8"},"source":["# Accuracy functions"]},{"cell_type":"code","metadata":{"id":"w3DcOM5uy77t","executionInfo":{"status":"ok","timestamp":1617532709638,"user_tz":-180,"elapsed":710,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}}},"source":["def get_count_from_logits(logits, labels):\n","\n","    probs = F.softmax(logits, dim=1)\n","    output = torch.argmax(probs, dim=1)\n","    \n","    count = (output == labels.squeeze()).long().sum()\n","\n","    return count.item(), labels.squeeze(1).size(-1)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vwK7eN5m6XyF"},"source":["# Install requirements "]},{"cell_type":"code","metadata":{"id":"W8K7v0CBVNfS","executionInfo":{"status":"ok","timestamp":1617532718173,"user_tz":-180,"elapsed":9236,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}}},"source":["%%capture\n","!pip install transformers tensorboard"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"oJFYAXLtTN2R","executionInfo":{"status":"ok","timestamp":1617532721604,"user_tz":-180,"elapsed":12666,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}}},"source":["%%capture\n","!pip install tensorflow"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5iwuV0kb6gs5"},"source":["# Set parameters "]},{"cell_type":"code","metadata":{"id":"Fyjx3X98BALi","executionInfo":{"status":"ok","timestamp":1617532721605,"user_tz":-180,"elapsed":12664,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}}},"source":["#@title Enviroments\n","from datetime import datetime\n","current_time = datetime.today().strftime('%Y-%m-%d-%H-%M-%S')\n","\n","language = 'ru' #@param [\"eng\", \"ru\", \"ROCStories\"]\n","hidden_layers = 0 #@param [0, 1, 2]\n","hidden_per_layer = 768 #@param [768, 1024] {type:\"raw\"}\n","bert_output = 'pooler' #@param ['pooler', 'last_hidden_state', 'concatenation']\n","bert_model_name = 'DeepPavlov/rubert-base-cased' #@param ['bert-base-uncased', 'DeepPavlov/rubert-base-cased', 'bert-large-uncased', 'bert-base-multilingual-cased']\n","\n","folder_name = \"1log_{}_{}_{}_{}_{}\".format(language, bert_model_name.split('/')[-1], bert_output, hidden_layers, hidden_per_layer)\n","if language=='eng':\n","    dataset_path = \"/content/drive/My Drive/Colab Notebooks/next_sentence/english_dataset\"\n","    log_path_base = \"/content/drive/My Drive/Colab Notebooks/next_sentence/logs/\"\n","    log_path = log_path_base+folder_name+\"/\"\n","\n","    training_set_filename = 'english_dataset_filtered_v2_train.json'\n","    test_set_filename = 'english_dataset_filtered_v2_test.json'\n","    test_samples_filename = 'english_dataset_filtered_v2_test_samples.json'\n","\n","elif language=='ru':\n","    dataset_path = \"/content/drive/My Drive/Colab Notebooks/next_sentence/russian_dataset\"\n","    log_path_base = \"/content/drive/My Drive/Colab Notebooks/next_sentence/logs/\"\n","    log_path = log_path_base+folder_name+\"/\"\n","\n","    training_set_filename = 'russian_dataset_filtered_train.json'\n","    test_set_filename = 'russian_dataset_filtered_test.json'\n","    test_samples_filename = 'russian_dataset_filtered_test_samples.json'\n","    \n","else:\n","    dataset_path = \"/content/drive/My Drive/Colab Notebooks/next_sentence/english_dataset\"\n","    log_path_base = \"/content/drive/My Drive/Colab Notebooks/next_sentence/logs/\"\n","    log_path = log_path_base+folder_name+\"/\"\n","\n","    training_set_filename = 'ROCStories_train.json'\n","    test_set_filename = 'ROCStories_test.json'\n","    test_samples_filename = 'ROCStories_test_samples.json'\n","\n","checkpoint_path = dataset_path+\"/1checkpoint_{}_{}_{}_{}_{}.pt\".format(language, bert_model_name.split('/')[-1], bert_output, hidden_layers, hidden_per_layer)\n","\n","step = 0"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"GKsigyqdn295","executionInfo":{"status":"ok","timestamp":1617532725521,"user_tz":-180,"elapsed":16578,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}}},"source":["from torch.utils.tensorboard import SummaryWriter\n","\n","# tb = SummaryWriter(log_dir=log_path+\"general_{}_{}_{}_{}_{}\".format(language, bert_model_name.split('/')[-1], bert_output, hidden_layers, hidden_per_layer))\n","# tb.add_text(\"Experiment_details\", \"Hidden layers: {:} \".format(hidden_layers))\n","# tb.add_text(\"Experiment_details\", \"Bert output utilized: {}\".format(bert_output))\n","# tb.add_text(\"Experiment_details\", \"Bert base model: {}\".format(bert_model_name.split('/')[-1]))\n","# tb.add_text(\"Experiment_details\", \"Hidden per layer: {:}\".format(hidden_per_layer))\n","# tb.add_text(\"Experiment_details\", \"Training set file: {}\".format(training_set_filename))\n","# tb.add_text(\"Experiment_details\", \"Test set file: {}\".format(test_set_filename))\n","# tb_training = SummaryWriter(log_dir=log_path+\"training_{}_{}_{}_{}_{}\".format(language, bert_model_name.split('/')[-1], bert_output, hidden_layers, hidden_per_layer))\n","# tb_validation = SummaryWriter(log_dir=log_path+\"validation_{}_{}_{}_{}_{}\".format(language, bert_model_name.split('/')[-1], bert_output, hidden_layers, hidden_per_layer))\n","# tb_test = SummaryWriter(log_dir=log_path+\"test_{}_{}_{}_{}_{}\".format(language, bert_model_name.split('/')[-1], bert_output, hidden_layers, hidden_per_layer))"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3OEh7i0hkHrc"},"source":["# Prepare dataset"]},{"cell_type":"code","metadata":{"id":"T7DlqBd3EvfA","executionInfo":{"status":"ok","timestamp":1617532725521,"user_tz":-180,"elapsed":16577,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}}},"source":["from os.path import join\n","import json\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"2V4HUh_IFlVh","executionInfo":{"status":"ok","timestamp":1617532726831,"user_tz":-180,"elapsed":17885,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}}},"source":["with open(join(dataset_path, training_set_filename), encoding='utf-8') as f:\n","    train_articles = json.load(f)\n","    train_articles = [a for a in train_articles if len(a['paragraphs'])>0 ]\n","\n","with open(join(dataset_path, test_set_filename), encoding='utf-8') as f:\n","    test_articles = json.load(f)\n","    test_articles = [a for a in test_articles if len(a['paragraphs'])>0 ]\n","\n","    "],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_sjCW3Xj23Oq","executionInfo":{"status":"ok","timestamp":1617532726832,"user_tz":-180,"elapsed":17872,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}},"outputId":"e99297ec-dee1-4a67-e9ef-15a2d99e645a"},"source":["print(len(train_articles))\n","if language == 'eng':\n","    # train_articles = train_articles[:600]\n","    pass\n","elif language == 'ru':\n","    # train_articles = train_articles[:1800]\n","    pass\n","else:\n","    pass"],"execution_count":9,"outputs":[{"output_type":"stream","text":["1871\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rt9apyvKHMm-","executionInfo":{"status":"ok","timestamp":1617532726832,"user_tz":-180,"elapsed":17870,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}}},"source":["# print(json.dumps(dataset[0], indent=4, ensure_ascii=False))"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jdrcdHr6IgT6"},"source":["Create the positive sample set"]},{"cell_type":"code","metadata":{"id":"OGlrI-fo6Po2","executionInfo":{"status":"ok","timestamp":1617532726833,"user_tz":-180,"elapsed":17870,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}}},"source":["from random import randrange, choice\n","\n","def get_random_sent_by_bm25(dataset, source_sentence):\n","    tokenized_query = source_sentence.split(\" \")\n","    top_n = 100 if len(sentence_corpus)>100 else len(sentence_corpus)\n","    cands = bm25.get_top_n(tokenized_query, sentence_corpus, n=top_n)\n","    refs = [source_sentence for i in range(top_n)]\n","    _, _, F1 = scorer.score(cands, refs, verbose=False)\n","    # print(F1)\n","    F1=F1.detach().cpu().numpy()\n","    # print(F1)\n","    # print(json.dumps(cands, indent=2))\n","\n","    for i in range(top_n):\n","        if F1[i]<0.7:\n","            return cands[i]\n","    return cands[top_n-1]\n","\n","def get_random_sent(dataset, exclude_a_index, exclude_p_index):\n","    target_a_index = randrange(len(dataset))\n","    if target_a_index==exclude_a_index: # same article\n","        paragraphs = dataset[target_a_index]['paragraphs']\n","        p_index = (exclude_p_index + len(paragraphs)//2) % len(paragraphs)\n","        return choice(paragraphs[p_index])\n","    else: # different article\n","        paragraphs = dataset[target_a_index]['paragraphs']\n","        paragraph = choice(paragraphs)\n","        sent = choice(paragraph)\n","        return sent\n","        \n","def get_samples(dataset):\n","    first_sentences = []\n","    second_sentences = []\n","    labels = []\n","    paragraph_list = [p for article in dataset for p in article['paragraphs']]\n","    sentence_list = [s for p in paragraph_list for s in p]\n","    word_list = [w for s in sentence_list for w in s.split(' ')]\n","    print(\"Total paragraphs: {}\".format(len(paragraph_list)))\n","    print(\"Total sentences: {}\".format(len(sentence_list)))\n","    print(\"Total words: {}\".format(len(word_list)))\n","    # Positive samples\n","    for paragraph in paragraph_list:\n","        for i in range(0,len(paragraph)-1):\n","            first_sentences.append(paragraph[i])\n","            second_sentences.append(paragraph[i+1])\n","            labels.append(0)\n","    # Negative samples\n","    for a_index, article in enumerate(dataset):\n","        for p_index, paragraph in enumerate(article['paragraphs']):\n","            for i in range(0,len(paragraph)):\n","                ch = randrange(4)\n","                if ch==0 and i<len(paragraph)-2:\n","                    first_sentences.append(paragraph[i])\n","                    second_sentences.append(paragraph[randrange(i+2,min(len(paragraph), i+4))])\n","                elif ch==1 and i<len(paragraph)-1:\n","                    first_sentences.append(paragraph[i+1])\n","                    second_sentences.append(paragraph[i])\n","                elif ch==2:\n","                    first_sentences.append(paragraph[i])\n","                    second_sentences.append(paragraph[i])\n","                else:\n","                    first_sentences.append(paragraph[i])\n","                    second_sentences.append(get_random_sent(dataset, a_index, p_index))\n","                labels.append(1)\n","    return first_sentences, second_sentences, labels"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mwJ8AjfHMktv","executionInfo":{"status":"ok","timestamp":1617532729004,"user_tz":-180,"elapsed":20031,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}},"outputId":"31a9f4c6-465a-48c1-8789-5573a5941605"},"source":["from sklearn.model_selection import train_test_split\n","import os.path\n","\n","# Get samples from training dataset\n","train_s1, train_s2, train_labels = get_samples(train_articles)\n","# Split sample set to training set and validation set\n","train_s1, val_s1,train_s2, val_s2, train_labels, val_labels = train_test_split(train_s1, train_s2, train_labels, train_size=0.8, test_size=0.2)\n","\n","# Get samples from test dataset\n","if not os.path.isfile(join(dataset_path, test_samples_filename)):\n","    test_s1, test_s2, test_labels = get_samples(test_articles)\n","    with open(join(dataset_path, test_samples_filename), 'w', encoding='utf-8') as f:\n","        json.dump({'s1': test_s1, 's2':test_s2, 'labels':test_labels}, f, ensure_ascii=False)\n","else:\n","    with open(join(dataset_path, test_samples_filename), encoding='utf-8') as f:\n","        test_json = json.load(f)\n","        test_s1 = test_json['s1']\n","        test_s2 = test_json['s2']\n","        test_labels = test_json['labels']\n","        test_json = None\n","\n","print(len(train_s1))\n","print(len(val_s1))\n","print(len(test_s1))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Total paragraphs: 22454\n","Total sentences: 92655\n","Total words: 1575472\n","130284\n","32572\n","4648\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"77zP-ZVsU62Q","colab":{"base_uri":"https://localhost:8080/","height":213,"referenced_widgets":["8d912b0ed7db4fecb93e6fa986f69975","1685947baaf04e799d6fc40b3be3e545","e49bfb4d143e4707bbac41eed4fa8022","49f5180d1e5247a8b28afa5d3c82ea9a","0de803f71b5a43129d65271c12704fb2","0b384e76c6e749fe8e72df8c557a56a9","dd47a499700145849c9894498ae95182","6d445b8a18744e02959b820658351fb2","c1f3e10975114d58b8417114371af6d2","5e9b1ed3c530486a901880495d4d4b54","2006e8a2a935484eb897fbad08134e63","e84fb36309a64db5a5971ec1485a41f6","c40fee287bf34269bd1dd96fcb0079cc","0245b63b9fc0458d96f0274ecc9ead7f","13290f90835d43e6a2bfcfe3087846b7","51118a83882d4db3ae9fb25afff5bd8f","9dc5b5456e524e4dbf06023429fb9104","2c5bdfcacf38484e9de3f3fe69c0189b","f9f045480bf04bf8b438116ad1843536","31b4ed55ec3849cbb66e98a2d97b500d","c80494ec9c78497b81da2535c6109ee5","14d4fd2e75454e2bbdd9edf850624d2d","8b1bed71822c4cd19a18bebcc654608b","04308c67dbd74d008ee5ec9153b91c93","d44a1e8a69ae4c7cbeb0349e5857c901","7a761fdf585e4a69b276fbfc42af68e6","e83c0a5005274b5893a5c57bcaca9aa1","526e63eb13eb48b99d7e4a1db12c47c7","dd853ba61682432b8ec06d9923922565","b1ad643b83ac49159282de271dc653f0","14d2f248b3b04fb7a05cfc27238a7d07","50c4430b84394efba997930a7022e4fb"]},"executionInfo":{"status":"ok","timestamp":1617532730737,"user_tz":-180,"elapsed":21753,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}},"outputId":"5ba0a346-d8ae-4c30-d26e-28dcb811ea7d"},"source":["from transformers import AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d912b0ed7db4fecb93e6fa986f69975","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=642.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c1f3e10975114d58b8417114371af6d2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1649718.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9dc5b5456e524e4dbf06023429fb9104","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d44a1e8a69ae4c7cbeb0349e5857c901","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1VQkJ6MbdX-d","executionInfo":{"status":"ok","timestamp":1617532746576,"user_tz":-180,"elapsed":37590,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}}},"source":["train_encodings = tokenizer(train_s1, train_s2, padding=False)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s-zimaUPcDxe","executionInfo":{"status":"ok","timestamp":1617532746577,"user_tz":-180,"elapsed":32937,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}},"outputId":"094943ad-5ffa-4563-e9e3-2d792cf09b2e"},"source":["c=0\n","t=0\n","for encodings in train_encodings['input_ids']:\n","    c+=1\n","    t+=len(encodings)\n","print(c,t)\n","print(t/c)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["130284 6740708\n","51.738571121549846\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q3Rs792DsYQa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613133571586,"user_tz":-180,"elapsed":44259,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}},"outputId":"1e27f1d5-92eb-4488-82cb-d10f75e5fb99"},"source":["%%time\n","train_encodings = tokenizer(train_s1, train_s2, truncation=True, padding=True, max_length=64)\n","val_encodings = tokenizer(val_s1, val_s2, truncation=True, padding=True, max_length=64)\n","test_encodings = tokenizer(test_s1, test_s2, truncation=True, padding=True, max_length=64)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CPU times: user 59.4 s, sys: 1.23 s, total: 1min\n","Wall time: 18.3 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ymgZB-uTdpo9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613133571587,"user_tz":-180,"elapsed":44249,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}},"outputId":"34db4166-f07d-4a8e-c880-f3441ec4bafb"},"source":["print(train_encodings['input_ids'][5], train_labels[5])\n","# print(train_encodings['input_ids'][7000], labels[7000])\n","\n","print(train_labels[:20])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[101, 845, 8092, 3299, 15459, 4627, 27209, 51553, 845, 304, 21506, 14067, 98715, 9176, 326, 128, 845, 304, 21506, 66089, 326, 2748, 14776, 21150, 68732, 2570, 128, 11267, 68732, 2237, 304, 39018, 6201, 102, 32157, 37789, 10887, 1638, 4415, 25817, 304, 110746, 70509, 326, 128, 48527, 2075, 15484, 22129, 1699, 4564, 845, 3689, 15484, 4161, 128, 130, 106472, 852, 128, 104088, 10058, 37789, 102] 1\n","[0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"epzUrvlTs3BB"},"source":["import torch\n","\n","class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, sentences1, sentences2, encodings, labels):\n","        self.sentences1 = sentences1\n","        self.sentences2 = sentences2\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx]).unsqueeze(0)\n","        item['sentence1'] = self.sentences1[idx]\n","        item['sentence2'] = self.sentences2[idx]\n","        \n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lFRyx3I4s_Rc"},"source":["train_dataset = CustomDataset(train_s1, train_s2, train_encodings, train_labels)\n","val_dataset = CustomDataset(val_s1, val_s2, val_encodings, val_labels)\n","test_dataset = CustomDataset(test_s1, test_s2, test_encodings, test_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XFxyb1P3Rbr4"},"source":["# Create model and training \n"]},{"cell_type":"markdown","metadata":{"id":"YyDwgoWhMHAS"},"source":["## Create model"]},{"cell_type":"code","metadata":{"id":"dqhxx3PytQWI"},"source":["import torch\n","import torch.nn as nn\n","from transformers import AutoConfig, AutoModel, BertModel \n","\n","class NextSentenceClassifier(nn.Module):\n","\n","    # bert_output = ['pooler', 'last_hidden_state', 'concatenation']\n","    def __init__(self, freeze_bert = True, bert_model_name='bert-base-uncased', hidden_per_layer=768, hidden_layers = 1, bert_output = 'pooler', state_dict=None):\n","        super(NextSentenceClassifier, self).__init__()\n","        #Instantiating BERT model object \n","        config = AutoConfig.from_pretrained(bert_model_name, output_hidden_states=True)\n","\n","        if state_dict is not None:\n","            self.bert_layer = BertModel(config)\n","        else:\n","            self.bert_layer = AutoModel.from_pretrained(bert_model_name, config=config)\n","\n","        self.hidden_layers = hidden_layers\n","        self.hidden_per_layer = hidden_per_layer\n","        self.bert_output = bert_output\n","\n","        #Freeze bert layers\n","        if freeze_bert:\n","            for p in self.bert_layer.parameters():\n","                p.requires_grad = False\n","        \n","        if bert_output=='concatenation':\n","            self.input_length = 768*4    \n","        else:\n","            if bert_model_name=='bert-large-uncased':\n","                self.input_length = 1024\n","            else:    \n","                self.input_length = 768\n","        \n","        # dense layer 1\n","        if hidden_layers == 0:\n","            self.fc1 = nn.Linear(self.input_length,2)\n","        else:\n","            self.fc1 = nn.Linear(self.input_length,self.hidden_per_layer)\n","        \n","        if hidden_layers!=0:\n","            # dropout layer\n","            self.dropout = nn.Dropout(0.1)\n","            # relu activation function\n","            self.relu =  nn.ReLU()\n","\n","        if hidden_layers == 1:\n","            # dense layer 2 (Output layer)\n","            self.fc2 = nn.Linear(self.hidden_per_layer,2)\n","        else:\n","            self.fc2 = nn.Linear(self.hidden_per_layer,self.hidden_per_layer)\n","        \n","        if hidden_layers>1:\n","            # dropout layer\n","            self.dropout2 = nn.Dropout(0.1)\n","        \n","        if hidden_layers == 2:\n","            # dense layer 2 (Output layer)\n","            self.fc3 = nn.Linear(self.hidden_per_layer,2)\n","\n","        if state_dict is not None:\n","            self.load_state_dict(state_dict)\n","\n","\n","    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n","        '''\n","        Inputs:\n","            -input_ids : Tensor of shape [B, T] containing token ids of sequences\n","            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n","        '''\n","\n","        if input_ids is None:\n","            input_ids = torch.zeros(1,64).long().to(device)\n","        if attention_mask is None:\n","            attention_mask = torch.zeros(1,64).long().to(device)\n","        if token_type_ids is None:\n","            token_type_ids = torch.zeros(1,64).long().to(device)\n","\n","        #Feeding the input to BERT model to obtain contextualized representations\n","        res = self.bert_layer(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, return_dict=True)\n","        \n","        #Obtaining the representation of [CLS] head\n","\n","        if self.bert_output == 'pooler':\n","            logits = res['pooler_output']\n","        elif self.bert_output == 'last_hidden_state':\n","            logits = res['last_hidden_state'][:,0]\n","        elif self.bert_output == 'concatenation':\n","            logits = torch.cat((res['hidden_states'][-4][:,0],res['hidden_states'][-3][:,0],res['hidden_states'][-2][:,0],res['hidden_states'][-1][:,0]),-1)\n","        else:\n","            raise ValueError('Value not supported')\n","\n","        logits = self.fc1(logits)\n","        if self.hidden_layers==1:\n","            logits = self.relu(logits)\n","            logits = self.dropout(logits)\n","            logits = self.fc2(logits)\n","        if self.hidden_layers==2:\n","            logits = self.relu(logits)\n","            logits = self.dropout2(logits)\n","            logits = self.fc3(logits)\n","\n","        return logits"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"27rg-n6HMJyJ"},"source":["## Training "]},{"cell_type":"code","metadata":{"id":"EhIqdZBu7Nd2"},"source":["def evaluate(model, validation_loader, step):\n","    model.eval()\n","    eval_accuracy = 0\n","    count = 0\n","    total_loss = 0\n","    with torch.no_grad():\n","        with tqdm(iter(validation_loader), total=len(validation_loader)) as t:\n","            for it, batch in enumerate(t):\n","                input_ids = batch['input_ids'].to(device)\n","                attention_mask = batch['attention_mask'].to(device)\n","                token_type_ids = batch['token_type_ids'].to(device)\n","                labels = batch['labels'].to(device)\n","                outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","                # outputs = model(input_ids, attention_mask=attention_mask)\n","                loss = criterion(outputs.view(-1, 2), labels.view(-1))\n","\n","                cnt, ttl = get_count_from_logits(outputs, labels)\n","                eval_accuracy += cnt\n","                total_loss += loss.item()\n","                count+=ttl\n","                t.set_description(\"Loss : {} Accuracy : {}\".format(total_loss/count, eval_accuracy/count))\n","            # tb_validation.add_scalar(\"Loss\", total_loss/count, step)\n","            # tb_validation.add_scalar(\"Accuracy\", eval_accuracy/count, step)\n","    return total_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Baus1oT-4yQZ"},"source":["def train(model, train_loader, step):\n","    model.train()\n","    eval_accuracy = 0\n","    count = 0\n","    total_loss = 0\n","    with tqdm(iter(train_loader), total=len(train_loader)) as t:\n","        for it, batch in enumerate(t):\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            token_type_ids = batch['token_type_ids'].to(device)\n","            labels = batch['labels'].to(device)\n","            \n","            outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","\n","            loss = criterion(outputs.view(-1, 2), labels.view(-1))\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","\n","            cnt, ttl = get_count_from_logits(outputs, labels)\n","            eval_accuracy += cnt\n","            total_loss += loss.item()\n","            count+=ttl\n","\n","            step+=1\n","            if (step) % 200 == 0:\n","                # tb_training.add_scalar(\"Loss\", total_loss/count, step)\n","                # tb_training.add_scalar(\"Accuracy\", eval_accuracy/count, step)\n","                t.set_description(\"Loss : {} Accuracy : {}\".format(total_loss/count, eval_accuracy/count))\n","                eval_accuracy = 0\n","                count = 0\n","                total_loss = 0\n","    return step"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aPhQHwDttE__","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["9af858736e57436c8bf00b4061b000a8","71375a55e46f43b9b697e6cbcb9f32d9","6695e654996844fc926d57125402324b","dc1b5060000248f785ddeb5ccee12b26","4dce73f5d53b4d3091aec693ce6a0f4e","9099753ede814d50a8ad2b4c7b20c8ed","88412f9281784227ad75a124bd1347da","f1220a3a788c4828979879bcc14216a5"]},"executionInfo":{"status":"ok","timestamp":1613133591244,"user_tz":-180,"elapsed":63884,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}},"outputId":"2e0ed8f4-7ad1-46a8-ca8b-3e468129a280"},"source":["from torch.utils.data import DataLoader\n","from transformers import AdamW\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","import torch.nn.functional as F\n","from transformers import get_linear_schedule_with_warmup\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","model = NextSentenceClassifier(freeze_bert = False, bert_model_name=bert_model_name, hidden_per_layer=hidden_per_layer, hidden_layers=hidden_layers, bert_output=bert_output)\n","# model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n","model.to(device)\n","model.train()\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","validation_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n","# optim = AdamW(model.parameters(), lr=5e-5)\n","criterion = nn.CrossEntropyLoss(reduction='sum').to(device)\n","\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)\n","\n","if language == 'ROCStories':\n","    total_epochs = 1\n","else:\n","    total_epochs = 1\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_epochs*len(train_loader))\n","\n","min_eval_loss = 9999999"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9af858736e57436c8bf00b4061b000a8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=711456796.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NMow-J5S9nCY"},"source":["### Actual training "]},{"cell_type":"code","metadata":{"id":"NFDD6btp7eHZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613133629957,"user_tz":-180,"elapsed":102586,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}},"outputId":"bc7d912c-28da-435a-bfe5-e34068d3c251"},"source":["evaluate(model, validation_loader, step)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loss : 0.6887256913815788 Accuracy : 0.5550165786565148: 100%|██████████| 1018/1018 [00:38<00:00, 26.22it/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["22433.173219680786"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"RT_uGAZkI1By","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613134196715,"user_tz":-180,"elapsed":669334,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}},"outputId":"d5311901-f41f-49af-ccf2-a92284adc137"},"source":["for epoch in range(total_epochs):\n","    # Training\n","    print(\"\")\n","    print(\"Epoch: {}\".format(epoch+1), flush=True, end=' ')\n","    step = train(model, train_loader, step)\n","    # Evaluation\n","    eval_loss = evaluate(model, validation_loader, step)\n","    if eval_loss<min_eval_loss:\n","        min_eval_loss = eval_loss\n","        # torch.save({\n","        #     'language':language ,\n","        #     'bert_model_name':bert_model_name,\n","        #     'bert_output':bert_output,\n","        #     'hidden_layers':hidden_layers,\n","        #     'hidden_per_layer':hidden_per_layer,\n","        #     'epoch': epoch,\n","        #     'model_state_dict': model.state_dict()\n","        #     }, checkpoint_path)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Epoch: 1 "],"name":"stdout"},{"output_type":"stream","text":["Loss : 0.40648954272270205 Accuracy : 0.7990625: 100%|██████████| 4072/4072 [08:47<00:00,  7.71it/s]\n","Loss : 0.38953482748966434 Accuracy : 0.8136436202873634: 100%|██████████| 1018/1018 [00:38<00:00, 26.26it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ZAK3tmMRHvMX"},"source":["# tb.add_graph(model, torch.zeros(1,64).long().cuda())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c8lQdeIV8X4g"},"source":["# Details on test set"]},{"cell_type":"markdown","metadata":{"id":"lonNAd7Xhwot"},"source":["## Load model from checkpoint"]},{"cell_type":"code","metadata":{"id":"b2AZiRG2h0oo"},"source":["# import torch \n","# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","# checkpoint = torch.load(checkpoint_path, map_location='cpu')\n","\n","# model = NextSentenceClassifier(\n","#     freeze_bert = True, \n","#     bert_model_name=checkpoint['bert_model_name'], \n","#     hidden_per_layer=checkpoint['hidden_per_layer'], \n","#     hidden_layers=checkpoint['hidden_layers'], \n","#     bert_output=checkpoint['bert_output'],\n","#     state_dict=checkpoint['model_state_dict']\n","#     ).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9cfF9Wz9etUn"},"source":["## Define helper functions"]},{"cell_type":"code","metadata":{"id":"3V_4evm8etBQ"},"source":["import textwrap\n","import itertools\n","def plot_confusion_matrix(cm, class_names, title=\"Confusion matrix\", x_label=\"Predicted label\", y_label=\"True label\", normalize=False, side_labels=False):\n","    \"\"\"\n","    Returns a matplotlib figure containing the plotted confusion matrix.\n","    \n","    Args:\n","       cm (array, shape = [n, n]): a confusion matrix of integer classes\n","       class_names (array, shape = [n]): String names of the integer classes\n","    \"\"\"\n","\n","    if side_labels:\n","        figure = plt.figure(figsize=(20, 10))\n","        ax1, ax2 = figure.subplots(1, 2)\n","    else:\n","        figure = plt.figure(figsize=(10,10))\n","        ax1 = figure.subplots(1,1)\n","\n","    im = ax1.imshow(cm, interpolation='nearest', cmap=plt.cm.Oranges, vmin=0)\n","    ax1.set_title(title,fontsize=24)\n","    plt.colorbar(im,ax=ax1)\n","    tick_marks = np.arange(len(class_names))\n","    ax1.set_xticks(tick_marks)\n","    ax1.set_yticks(tick_marks)\n","    if side_labels:\n","        ax1.set_xticklabels(tick_marks, rotation=45)\n","        ax1.set_yticklabels(tick_marks)\n","    else:\n","        ax1.set_xticklabels(class_names, rotation=45)\n","        ax1.set_yticklabels(class_names)\n","    \n","    if normalize:\n","        # Normalize the confusion matrix.\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        # Use white text if squares are dark; otherwise black.\n","    else:\n","        pass\n","\n","    threshold = cm.max() / 2.\n","    cm = np.around(cm, decimals=3)\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        color = \"white\" if cm[i, j] > threshold else \"black\"\n","        ax1.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n","        \n","    figure.tight_layout()\n","    ax1.set_ylabel(y_label)\n","    ax1.set_xlabel(x_label)\n","\n","    if side_labels:\n","        ax2.axis('off')\n","        side_text = \"\"\n","        for i, cls in enumerate(class_names):\n","            side_text+=textwrap.fill(\"{} - {}\".format(i,cls))+\"\\n\"\n","        ax2.text(0, 0.5, side_text, horizontalalignment=\"left\",fontsize=18, va='center', color='black', wrap=True)\n","\n","    return figure"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HZh5Bsm1fPkx"},"source":["import matplotlib.pyplot as plt\n","import io\n","import tensorflow as tf\n","def plot_to_image(figure, close=True):\n","    \"\"\"\n","    Converts the matplotlib plot specified by 'figure' to a PNG image and\n","    returns it. The supplied figure is closed and inaccessible after this call.\n","    \"\"\"\n","    \n","    buf = io.BytesIO()\n","    \n","    # Use plt.savefig to save the plot to a PNG in memory.\n","    plt.savefig(buf, format='png')\n","    \n","    # Closing the figure prevents it from being displayed directly inside\n","    # the notebook.\n","    if close:\n","        plt.close(figure)\n","        buf.seek(0)\n","        \n","        # Use tf.image.decode_png to convert the PNG buffer\n","        # to a TF image. Make sure you use 4 channels.\n","        image = tf.image.decode_png(buf.getvalue(), channels=3)\n","        \n","        return image\n","    else:\n","        return None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vzaMZ8kxuKDf"},"source":["## On neighboring-sentence level "]},{"cell_type":"markdown","metadata":{"id":"3YcwIzhyuRWq"},"source":["### Process data "]},{"cell_type":"code","metadata":{"id":"DMRihdDu8sdm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613134206666,"user_tz":-180,"elapsed":679267,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}},"outputId":"6b6902f9-bce4-49ac-e4cc-504dc06a5ec8"},"source":["from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","import torch.nn.functional as F\n","from sklearn.metrics import precision_recall_fscore_support\n","\n","\n","test_loader = DataLoader(test_dataset, batch_size=32)\n","\n","model.eval()\n","eval_accuracy = 0\n","count = 0\n","total_loss = 0\n","\n","criterion = nn.CrossEntropyLoss(reduction='sum').to(device)\n","\n","test_labels = []\n","test_answers = []\n","with tqdm(iter(test_loader), total=len(test_loader)) as t:\n","    for it, batch in enumerate(t):\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        token_type_ids = batch['token_type_ids'].to(device)\n","        labels = batch['labels'].to(device)\n","        first = batch['sentence1']\n","        second = batch['sentence2']\n","\n","        outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        \n","        probs = F.softmax(outputs, dim=1)\n","        model_answer = torch.argmax(probs, dim=1)\n","        \n","        test_labels.append(labels)\n","        test_answers.append(model_answer)\n","\n","        for i in range(len(first)):\n","            tag = \"Positive sample\"\n","            if model_answer[i]==0:\n","                tag = \"Negative sample\"\n","            # tb_test.add_text(tag, \"1st: {}  \\n2nd:  {}  \\nProbability: {}  \\nModel answer: {}  \\nTrue label: {}\".format(\n","            #     first[i], second[i], probs[i].detach().cpu().numpy(), model_answer[i].detach().cpu().numpy(),labels[i].cpu().numpy()), \n","            #     global_step = step )\n","        \n","        loss = criterion(outputs.view(-1, 2), labels.view(-1))\n","\n","        # print(outputs, labels)\n","        cnt, ttl = get_count_from_logits(outputs, labels)\n","        eval_accuracy += cnt\n","        total_loss += loss.item()\n","        count+=ttl\n","        t.set_description(\"Loss : {} Accuracy : {}\".format(total_loss/count, eval_accuracy/count))\n","    # tb_test.add_text(\"Loss\", str(total_loss/count), global_step = step )\n","    # tb_test.add_text(\"Accuracy\", str(eval_accuracy/count), global_step = step)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loss : 0.34142061072544366 Accuracy : 0.8442340791738382: 100%|██████████| 146/146 [00:08<00:00, 18.06it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Szk265wxofRT"},"source":["test_labels = torch.cat(test_labels).cpu().numpy()\n","test_answers = torch.cat(test_answers).cpu().numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C-cLNLMzt-Fp"},"source":["### Neighboring Sentence Result "]},{"cell_type":"code","metadata":{"id":"u_Q9ocLcfkn6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613134206667,"user_tz":-180,"elapsed":679256,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}},"outputId":"6132f4f6-50af-45d1-de2d-f8f3913cc88f"},"source":["from sklearn.metrics import confusion_matrix, accuracy_score, matthews_corrcoef\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import itertools\n","import io\n","import tensorflow as tf\n","\n","cm = confusion_matrix(test_labels, test_answers)\n","# figure = plot_confusion_matrix(cm, class_names=[\"True\", \"False\"], title=\"Accuracy: {:3f}\\nMc: {:3f}\".format(accuracy_score(test_labels, test_answers), matthews_corrcoef(test_labels, test_answers)))\n","# cm_image = plot_to_image(figure)\n","\n","print(cm[1][1],cm[0][0],cm[1][0],cm[0][1])\n","\n","a,b,c,d = precision_recall_fscore_support(test_labels, test_answers, labels=[0,1])\n","print(a[1],b[1],c[1],d,\"\\n\")\n","# tb_test.add_image(\"Neighboring sentence-pair classification result\", cm_image.numpy(), global_step=step, dataformats='HWC')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2235 1689 407 317\n","0.8757836990595611 0.8459500378501136 0.8606083943011167 [2006 2642] \n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"I6jdrFiLur0Q"},"source":["## On paragraph level \n"]},{"cell_type":"markdown","metadata":{"id":"LfbvKilDv-e8"},"source":["### Examine sentence level relation in paragraph"]},{"cell_type":"code","metadata":{"id":"9uOMrzhqsLWY"},"source":["from itertools import product\n","import numpy as np\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","def create_paragraph_matrix(model, paragraph, mask=None, threshold=0.5):\n","\n","    if mask is not None:\n","        height = len(mask)\n","        width = len(mask[0])\n","        pair_index = []\n","        first_sentences = []\n","        second_sentences = []\n","        for i in range(height):\n","            for j in range(width):\n","                if mask[i][j]==1:\n","                    pair_index.append(i*width+j)\n","                    first_sentences.append(paragraph[i])\n","                    second_sentences.append(paragraph[j])\n","    else:\n","        combinations = list(product(paragraph, paragraph))\n","        first_sentences = [pair[0] for pair in combinations]\n","        second_sentences = [pair[1] for pair in combinations]\n","    total_elements = len(second_sentences)\n","    labels = [0]*total_elements\n","\n","    encodings = tokenizer(first_sentences, second_sentences, truncation=True, padding=True, max_length=64)\n","    ds = CustomDataset(first_sentences, second_sentences, encodings, labels)\n","    loader = DataLoader(ds, batch_size=32, shuffle=False)\n","\n","    results = []\n","    model.eval()\n","    with torch.no_grad():\n","        # with tqdm(iter(loader), total=len(loader),leave=False) as t:\n","        for it, batch in enumerate(loader):\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            token_type_ids = batch['token_type_ids'].to(device)\n","            labels = batch['labels'].to(device)\n","            outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","\n","            probs = F.softmax(outputs, dim=1)\n","            probs = probs[:,0]\n","            results.append(probs)\n","            \n","    if mask is not None:\n","        results = torch.cat(results).detach().cpu().numpy()\n","        temp = [0]*(width*height)\n","        for i, val in enumerate(results):\n","            temp[pair_index[i]]=1 if val>threshold else 0\n","\n","        results = np.reshape(temp, (len(paragraph), len(paragraph)))\n","    else:\n","        results = torch.cat(results)\n","        results = torch.reshape(results, (len(paragraph), len(paragraph))).detach().cpu().numpy()\n","\n","    return results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ZeB6Avfuu9Y"},"source":["# p_index = 0\n","# for article in test_articles:\n","#     for paragraph in article['paragraphs']:\n","#         matrix = create_paragraph_matrix(model, paragraph)\n","#         figure = plot_confusion_matrix(matrix, \n","#                                     title=\"Sentence relation\", \n","#                                     y_label=\"First sentence\", \n","#                                     x_label=\"Second sentence\", \n","#                                     class_names=paragraph, \n","#                                     normalize=False, \n","#                                     side_labels=True)\n","#         cm_image = plot_to_image(figure)\n","#         tb_test.add_image(\"Sentence relation within paragraph\", cm_image.numpy(), global_step=p_index, dataformats='HWC')\n","        \n","#         p_index+=1\n","#         if p_index>50:\n","#             break\n","#     if p_index>50:\n","#         break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-t6FTg8HUw7G"},"source":["# print(p_index)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3GKScYkNyaxi"},"source":["# We work with the CAD routine CylindricalAlgebraicDecompose: part of the RegularChains Library for Maple. \n","# It builds decompositions first of Cn before refining to a CAD of Rn.  \n","# We ran the code in Maple 2018 but used an updated version of the RegularChains Library.  \n","# Brown's heuristic and the features for ML were coded in the sympy package v1.3 for Python 2.7.  \n","# The sotd} heuristic was implemented in Maple as part of the ProjectionCAD package EWBD14. \n","# Training and evaluation of the ML models was done using the scikit-learn package v0.20.2 for Python 2.7.  \n","# In order to implement our adapted cross-validation procedure we had to rewrite a number of the standard commands within the package to both use the redefined hopt in, and to access the data it requires during the cross-validation.\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-9fsM4-L0s2O"},"source":["# We use our algorithm to approximate the coefficients of some small dimension hammocks, i.e., the 3×5, and the 5×5 hammocks. \n","# The implementation of the algorithm was done in Maple software. \n","# The exact reliability polynomials considered here are taken from. \n","# We also compute upper and lower bounds for such networks, more exactly Stanley type of bounds (see), denoted by"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ztNVZHGtwIme"},"source":["### Classify paragraphs and detect unrelated sentences with and without sentence-distance "]},{"cell_type":"code","metadata":{"id":"H4np_auG1XAb"},"source":["import json\n","# matrix = [[0,1,1,0,0,0],\n","#           [0,0,0,0,0,0],\n","#           [0,1,0,1,0,0],\n","#           [0,1,0,0,1,0],\n","#           [0,1,0,0,0,1],\n","#           [0,1,0,0,0,0]]\n","def create_mask_matrix(sizeY, sizeX, distance):\n","    masked_matrix = [[0 for col in range(sizeX)] for row in range(sizeY)]\n","    cell_list = []\n","    for i in range(sizeY):\n","        for j in range(sizeX):\n","            if j>i and j-i<=distance:\n","                masked_matrix[i][j] = 1\n","                cell_list.append([i,j])\n","            else:\n","                masked_matrix[i][j] = 0\n","    return masked_matrix, cell_list\n","\n","def mask_paragraph_matrix(matrix, distance, threshold=0.5):\n","    masked_matrix = [row[:] for row in matrix]\n","    height = len(masked_matrix)\n","    width = len(masked_matrix[0])\n","    cell_list = []\n","    for i in range(height):\n","        for j in range(width):\n","            if j>i and j-i<=distance:\n","                if masked_matrix[i][j]>threshold:\n","                    masked_matrix[i][j] = 1\n","                    cell_list.append([i,j])\n","                else:\n","                    masked_matrix[i][j] = 0\n","            else:\n","                masked_matrix[i][j] = 0\n","    return masked_matrix, cell_list\n","\n","def cluster_paragraph_matrix(number_elements, edges):\n","    elements = [[i] for i in range(number_elements)]\n","    def find(i):\n","        for arr in elements:\n","            if i in arr:\n","                return arr\n","        return None\n","    def union(set1, set2):\n","        new_set = [*set1, *set2]\n","        elements.remove(set1)\n","        elements.remove(set2)\n","        elements.append(new_set)\n","\n","    for edge in edges:\n","        if find(edge[0]) != find(edge[1]):\n","            union(find(edge[0]), find(edge[1]))\n","    \n","    return elements\n","\n","# masked_arr, cell_list = mask_paragraph_matrix(matrix, 1)\n","# clusters = cluster_paragraph_matrix(len(masked_arr), cell_list)\n","# large_cluster = max(clusters, key=lambda item: len(item))\n","# unrelated = [e for arr in clusters for e in arr if arr!=large_cluster]\n","# print(matrix)\n","# print(masked_arr)\n","# print(cells)\n","# print(clusters)\n","# print(large_cluster)\n","# print(unrelated)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dtLUSslRaamh"},"source":["def process_paragraph(model, paragraph, distance=1, cmatrix=None, generate_full_matrix=True, threshold=0.5):\n","    if cmatrix is not None:\n","        matrix = cmatrix\n","    else:\n","        if generate_full_matrix:\n","            matrix = create_paragraph_matrix(model, paragraph)\n","        else:\n","            masked_arr, cell_list = create_mask_matrix(len(paragraph),len(paragraph), distance)\n","            matrix = create_paragraph_matrix(model, paragraph, mask=masked_arr, threshold=threshold)\n","\n","    # process the matrix\n","    masked_arr, cell_list = mask_paragraph_matrix(matrix, distance,threshold=threshold)\n","    clusters = cluster_paragraph_matrix(len(masked_arr), cell_list)\n","    large_cluster = max(clusters, key=lambda item: len(item))\n","    # unrelated_sentences = [e for arr in clusters for e in arr if arr!=large_cluster]\n","    unrelated_sentences = [e for arr in clusters for e in arr if len(arr)==1]\n","    \n","\n","    # overall connection is satisfied if there are no unrelated sentence\n","    paragraph_connection = 1 if len(unrelated_sentences)>0 else 0\n","\n","    # convert array of indexes to marking\n","    unrelated_sentences = [ 1 if i in unrelated_sentences else 0 for i in range(len(masked_arr))]\n","    return paragraph_connection, unrelated_sentences # indexes of unrelated sentences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Gu6t4bcXPkQ"},"source":["%%capture\n","!pip install bert_score\n","!pip install rank_bm25"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j5Mj_FNFYE0u","colab":{"base_uri":"https://localhost:8080/","height":164,"referenced_widgets":["c4237b8a2df24a99af284c5bd5af528a","3b07d7fdfd3a4cc9ae8c6d1510e122ed","c02839a1422f4cf69869d08ee617af0e","a4bef0b1efb1434486b34cebbcd03a99","6bc9c85af621442490f63415d39239b5","b4dea257100c4c08a6cae232e2052dd9","e09b7f1ac3b54a328535fe877ee30e7d","d278dab3ff6f4084960cb28ff4b20361","8fd73873285b4f2982cf94a73bb88181","34cef223c90246acafd0aab2ac3206d2","15b710c8ba4a4984bf3d7225db28a2d5","4a57c1a658f047399994c9909e5b487c","ab7159d6db0a4fd1b1f725f6da5ccd37","f5f6fe10a3fd4f3288c2d1fe9e8aa2bd","52f3dea741d44d8a91fabd21a9af3bfd","0dbd2f2d34d64e5ea1f9d329f2d9226e","eae0d830d0c541b08cce2d7826575c23","6d61c5544cd74621bd12e65d76f90194","02f1afb1690d45ba8733ef1e4888157c","be89845856b7438ba7ddbda16f90edff","c1469f81563341e890e7b688916c6ce8","4a88e873914d419883105c6065d72ae5","dc4331a83267411d9da13b94de9ecce0","f0d7db45eeaf461f89439b873c03619b"]},"executionInfo":{"status":"ok","timestamp":1613134226336,"user_tz":-180,"elapsed":698899,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}},"outputId":"600c3fe9-2fee-48ab-e567-c3ee84aa9c6d"},"source":["import random\n","from tqdm import tqdm\n","from sklearn.metrics import confusion_matrix, accuracy_score, matthews_corrcoef\n","\n","from rank_bm25 import BM25Okapi\n","from bert_score import BERTScorer\n","\n","sentence_corpus = [s for a in test_articles for p in a['paragraphs'] for s in p]\n","tokenized_sentence_corpus = [doc.split(\" \") for doc in sentence_corpus]\n","bm25 = BM25Okapi(tokenized_sentence_corpus)\n","if language=='ROCStories' or language=='eng':\n","    scorer = BERTScorer(lang='en')\n","else:\n","    scorer = BERTScorer(lang='ru')\n","\n","def run_paragraph_classification_test(distance = 1, threshold = 0.5):\n","    total_images = 0\n","    paragraph_labels = []\n","    paragraph_predictions = []\n","\n","    sentence_labels = []\n","    sentence_predictions = []\n","    with tqdm(iter(test_articles), total=len(test_articles),leave=True) as t:\n","        for a_index, article in enumerate(t):\n","            for p_index, paragraph in enumerate(article['paragraphs']):\n","                # random label\n","                label = 1 # random.randrange(2)\n","                # create sample accordingly\n","                sample = [s for s in paragraph]\n","\n","                unrelated_sentence_indexes = []\n","                if label==0:\n","                    pass\n","                elif label==1:\n","                    if language=='ROCStories':\n","                        index = randrange(len(sample))\n","                        unrelated_sentence = get_random_sent_by_bm25(test_articles, sample[index])\n","                        sample[index] = unrelated_sentence\n","                        unrelated_sentence_indexes.append(index)\n","                    elif language=='eng':\n","                        numbers_of_unrelated = min(randrange(1,3),len(sample)//2)\n","                        for i in range(numbers_of_unrelated):\n","                            index = randrange(len(sample))\n","                            unrelated_sentence = get_random_sent_by_bm25(test_articles, sample[index])\n","                            sample[index] = unrelated_sentence\n","                            unrelated_sentence_indexes.append(index)\n","                    else:\n","                        numbers_of_unrelated = 1 #min(randrange(1,3),len(sample)//2)\n","                        for i in range(numbers_of_unrelated):\n","                            index = randrange(len(sample))\n","                            unrelated_sentence = get_random_sent(test_articles, a_index, p_index)\n","                            sample[index] = unrelated_sentence\n","                            unrelated_sentence_indexes.append(index)\n","                            \n","                    #         unrelated_sentence = get_random_sent(test_articles, a_index, p_index)\n","                    #         index = randrange(len(sample))\n","                    #         sample.insert(index, unrelated_sentence)\n","                    #         unrelated_sentence_indexes = [a if a<index else a+1 for a in unrelated_sentence_indexes]\n","                    #         unrelated_sentence_indexes.append(index)\n","\n","                # if distance==1 and total_images<50:\n","                #     matrix = create_paragraph_matrix(model, sample)\n","                #     figure = plot_confusion_matrix(matrix, \n","                #                                 title=\"Sentence relation\", \n","                #                                 y_label=\"First sentence\", \n","                #                                 x_label=\"Second sentence\", \n","                #                                 class_names=sample, \n","                #                                 normalize=False, \n","                #                                 side_labels=True)\n","                #     cm_image = plot_to_image(figure)\n","                #     # tb_test.add_image(\"Sentence relation within paragraph\", cm_image.numpy(), global_step=total_images, dataformats='HWC')\n","                    \n","                #     total_images+=1\n","\n","                # process_paragraph (f(sample) -> label, unrelated_sentence_indexes)\n","                connection_pred, sentence_pred = process_paragraph(model, sample, distance=distance, generate_full_matrix=False,threshold=threshold)\n","\n","                # check inserted sentence indexes in case of negative samples (unrelated_pred, compare to unrelated_sentence_indexes)\n","                # if label==1 and label==connection_pred:\n","                sentence_labels.extend([ 1 if i in unrelated_sentence_indexes else 0 for i in range(len(sample))])\n","                sentence_predictions.extend(sentence_pred)\n","\n","                # check label\n","                paragraph_labels.append(label)\n","                paragraph_predictions.append(connection_pred)\n","                \n","    # cm = confusion_matrix(paragraph_labels, paragraph_predictions)\n","    # # figure = plot_confusion_matrix(cm, class_names=[\"Not containing unrelated sentence\", \"Containing unrelated sentence\"], title=\"Accuracy: {:3f}\\nMc: {:3f}\".format(\n","    # #     accuracy_score(paragraph_labels, paragraph_predictions), matthews_corrcoef(paragraph_labels, paragraph_predictions)))\n","    # # cm_image = plot_to_image(figure)\n","\n","    # print(cm[1][1],cm[0][0],cm[1][0],cm[0][1])\n","\n","    # a,b,c,d = precision_recall_fscore_support(paragraph_labels, paragraph_predictions, labels=[0,1])\n","    # print(a[1],b[1],c[1],d,\"\\n\")\n","\n","    # tb_test.add_image(\"Paragraph classification\", cm_image.numpy(), global_step=distance, dataformats='HWC')\n","\n","    cm = confusion_matrix(sentence_labels, sentence_predictions)\n","    # figure = plot_confusion_matrix(cm, class_names=[\"Ok sentences\", \"Unrelated sentences\"], title=\"Accuracy: {:3f}\\nMc: {:3f}\".format(\n","    #     accuracy_score(sentence_labels, sentence_predictions), matthews_corrcoef(sentence_labels, sentence_predictions)))\n","    # cm_image = plot_to_image(figure)\n","\n","    print(cm[1][1],cm[0][0],cm[1][0],cm[0][1])\n","\n","    a,b,c,d = precision_recall_fscore_support(sentence_labels, sentence_predictions, labels=[0,1])\n","    print(a[1],b[1],c[1],d,\"\\n\")\n","    # tb_test.add_image(\"Unrelated sentence detection in case of negative sample\", cm_image.numpy(), global_step=distance, dataformats='HWC')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c4237b8a2df24a99af284c5bd5af528a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8fd73873285b4f2982cf94a73bb88181","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eae0d830d0c541b08cce2d7826575c23","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714314041.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"15LCyjWpODIn"},"source":["### Paragraph Classification and Incoherent Sentence Detection"]},{"cell_type":"code","metadata":{"id":"aIZpVuIBQxnV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613134590603,"user_tz":-180,"elapsed":1063158,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}},"outputId":"b0fcb7a5-065a-43f1-cc3d-d9b19b948741"},"source":["for i in range(10):\n","    # for j in range(6):\n","    run_paragraph_classification_test(i+1, threshold=0.5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 209/209 [00:30<00:00,  6.90it/s]\n","  0%|          | 0/209 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["1953 4951 176 1690\n","0.5360966236618172 0.9173320807891029 0.6767151767151768 [6641 2129] \n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 209/209 [00:33<00:00,  6.22it/s]\n","  0%|          | 0/209 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["1868 5999 261 642\n","0.7442231075697211 0.8774072334429309 0.8053459797370123 [6641 2129] \n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 209/209 [00:34<00:00,  5.99it/s]\n","  0%|          | 0/209 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["1843 6116 286 525\n","0.778293918918919 0.8656646312822922 0.8196575494774294 [6641 2129] \n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 209/209 [00:35<00:00,  5.83it/s]\n","  0%|          | 0/209 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["1819 6109 310 532\n","0.773713313483624 0.8543917332080789 0.8120535714285715 [6641 2129] \n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 209/209 [00:36<00:00,  5.70it/s]\n","  0%|          | 1/209 [00:00<00:21,  9.70it/s]"],"name":"stderr"},{"output_type":"stream","text":["1780 6125 349 516\n","0.7752613240418118 0.8360732738374824 0.8045197740112994 [6641 2129] \n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 209/209 [00:38<00:00,  5.47it/s]\n","  0%|          | 1/209 [00:00<00:20,  9.94it/s]"],"name":"stderr"},{"output_type":"stream","text":["1797 6143 332 498\n","0.7830065359477124 0.8440582433067167 0.8123869801084991 [6641 2129] \n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 209/209 [00:38<00:00,  5.38it/s]\n","  0%|          | 1/209 [00:00<00:23,  8.92it/s]"],"name":"stderr"},{"output_type":"stream","text":["1801 6150 328 491\n","0.7857766143106457 0.8459370596524189 0.8147477946166026 [6641 2129] \n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 209/209 [00:38<00:00,  5.41it/s]\n","  0%|          | 0/209 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["1799 6103 330 538\n","0.7697903294822422 0.8449976514795678 0.80564263322884 [6641 2129] \n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 209/209 [00:38<00:00,  5.42it/s]\n","  0%|          | 1/209 [00:00<00:24,  8.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["1804 6139 325 502\n","0.782307025151778 0.8473461719116956 0.8135287485907553 [6641 2129] \n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 209/209 [00:38<00:00,  5.40it/s]"],"name":"stderr"},{"output_type":"stream","text":["1813 6135 316 506\n","0.7818025010780509 0.8515735086895256 0.8151978417266187 [6641 2129] \n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"fCFwCBMSJkIw"},"source":["## Missing Sentence\n"]},{"cell_type":"code","metadata":{"id":"eUxkF4NvJqeo"},"source":["def process_paragraph2(model, paragraph, distance=1, cmatrix=None, generate_full_matrix=True,threshold=0.5):\n","    if cmatrix is not None:\n","        matrix = cmatrix\n","    else:\n","        if generate_full_matrix:\n","            matrix = create_paragraph_matrix(model, paragraph)\n","        else:\n","            masked_arr, cell_list = create_mask_matrix(len(paragraph),len(paragraph), distance)\n","            matrix = create_paragraph_matrix(model, paragraph, mask=masked_arr, threshold=threshold)\n","\n","    # process the matrix\n","    masked_arr, cell_list = mask_paragraph_matrix(matrix, distance,threshold=threshold)\n","    clusters = cluster_paragraph_matrix(len(masked_arr), cell_list)\n","    large_cluster = max(clusters, key=lambda item: len(item))\n","    unrelated_sentences = [e for arr in clusters for e in arr if len(arr)==1]\n","    \n","    # convert array of indexes to marking\n","    unrelated_sentences = [ 1 if i in unrelated_sentences else 0 for i in range(len(masked_arr))]\n","\n","    cluster_marking = [0 for i in range(len(masked_arr))]\n","    for cls_i, cls in enumerate(clusters):\n","        for i in cls:\n","            cluster_marking[i]=cls_i\n","\n","    # print(clusters)\n","    missing_sentences = [ 1 if cluster_marking[i]!=cluster_marking[i+1] and (len(clusters[cluster_marking[i]])>1 or len(clusters[cluster_marking[i+1]])>1) else 0 for i in range(len(cluster_marking)-1)]\n","    \n","    # overall connection is satisfied if there are no unrelated sentence\n","    paragraph_connection = 1 if 1 in missing_sentences else 0\n","\n","    # print(missing_sentences)\n","    return paragraph_connection, unrelated_sentences, missing_sentences # marking array ( [0,1,0,0 ...] )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MEovWXMAJqev"},"source":["import random\n","from tqdm import tqdm\n","from sklearn.metrics import confusion_matrix, accuracy_score, matthews_corrcoef\n","\n","def run_paragraph_classification_test2(distance = 1, threshold=0.5):\n","    # total_images = 0\n","    paragraph_labels = []\n","    paragraph_predictions = []\n","\n","    sentence_labels = []\n","    sentence_predictions = []\n","    with tqdm(iter(test_articles), total=len(test_articles),leave=True) as t:\n","        for a_index, article in enumerate(t):\n","            for p_index, paragraph in enumerate([x for x in article['paragraphs'] if len(x)>2]):\n","                # random label\n","                label = 1 #random.randrange(2)\n","                # create sample accordingly\n","                sample = [s for s in paragraph]\n","                # print(len(sample))\n","                gap_indexes = []\n","                if label==0:\n","                    pass\n","                elif label==1:\n","                    if language=='ROCStories':\n","                        index = randrange(1,len(sample)-1)\n","                        sample.pop(index) \n","                        gap_indexes.append(index-1)\n","                    else:\n","                        numbers_of_unrelated = 1 #min(randrange(1,3),len(sample)//2)\n","                        for i in range(numbers_of_unrelated):\n","                            index = randrange(1,len(sample)-1)\n","                            sample.pop(index)\n","                            gap_indexes.append(index-1)\n","\n","                # process_paragraph (f(sample) -> label, unrelated_sentence_indexes)\n","                connection_pred, sentence_pred, missing_pred = process_paragraph2(model, sample, distance=distance, generate_full_matrix=False, threshold=threshold)\n","\n","                # check inserted sentence indexes in case of negative samples (unrelated_pred, compare to unrelated_sentence_indexes)\n","                # if label==1 and label==connection_pred:\n","                sentence_labels.extend([ 1 if i in gap_indexes else 0 for i in range(len(sample)-1)])\n","                sentence_predictions.extend(missing_pred)\n","\n","                # print([ 1 if i in gap_indexes else 0 for i in range(len(sample)-1)])\n","                # check label\n","                paragraph_labels.append(label)\n","                paragraph_predictions.append(connection_pred)\n","                # print(\" \")\n","                \n","    # cm = confusion_matrix(paragraph_labels, paragraph_predictions, labels=[0,1])\n","    # # figure = plot_confusion_matrix(cm, class_names=[\"Not containing unrelated sentence\", \"Containing unrelated sentence\"], title=\"Accuracy: {:3f}\\nMc: {:3f}\".format(\n","    # #     accuracy_score(paragraph_labels, paragraph_predictions), matthews_corrcoef(paragraph_labels, paragraph_predictions)))\n","    # # cm_image = plot_to_image(figure)\n","\n","    # print(cm)\n","    # print(cm[1][1],cm[0][0],cm[1][0],cm[0][1])\n","\n","    # a,b,c,d = precision_recall_fscore_support(paragraph_labels, paragraph_predictions, labels=[0,1])\n","    # print(a[1],b[1],c[1],d,\"\\n\")\n","\n","    # tb_test.add_image(\"Paragraph classification\", cm_image.numpy(), global_step=distance, dataformats='HWC')\n","\n","    cm = confusion_matrix(sentence_labels, sentence_predictions, labels=[0,1])\n","    # figure = plot_confusion_matrix(cm, class_names=[\"Ok sentences\", \"Unrelated sentences\"], title=\"Accuracy: {:3f}\\nMc: {:3f}\".format(\n","    #     accuracy_score(sentence_labels, sentence_predictions), matthews_corrcoef(sentence_labels, sentence_predictions)))\n","    # cm_image = plot_to_image(figure)\n","\n","    print(cm[1][1],cm[0][0],cm[1][0],cm[0][1])\n","\n","    a,b,c,d = precision_recall_fscore_support(sentence_labels, sentence_predictions, labels=[0,1])\n","    print(a[1],b[1],c[1],d,\"\\n\")\n","    # tb_test.add_image(\"Unrelated sentence detection in case of negative sample\", cm_image.numpy(), global_step=distance, dataformats='HWC')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qJyvvnV1PMZ4"},"source":["### Missing Sentence Result "]},{"cell_type":"code","metadata":{"id":"uKNUuj8wJqev","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613134757848,"user_tz":-180,"elapsed":1230391,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}},"outputId":"b793ee8b-de4a-4347-fc48-35e7c4e574ce"},"source":["for i in range(5):\n","    # for j in range(6):\n","    run_paragraph_classification_test2(i+1, threshold=0.5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 209/209 [00:31<00:00,  6.56it/s]\n","  0%|          | 0/209 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["321 2079 1808 304\n","0.5136 0.15077501174260216 0.23311546840958602 [2383 2129] \n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 209/209 [00:32<00:00,  6.35it/s]\n","  0%|          | 0/209 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["176 2233 1953 150\n","0.5398773006134969 0.08266791921089714 0.1433808553971487 [2383 2129] \n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 209/209 [00:33<00:00,  6.23it/s]\n","  0%|          | 0/209 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["128 2278 2001 105\n","0.5493562231759657 0.060122123062470646 0.1083827265029636 [2383 2129] \n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 209/209 [00:34<00:00,  6.12it/s]\n","  0%|          | 0/209 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["136 2295 1993 88\n","0.6071428571428571 0.06387975575387506 0.11559711007224818 [2383 2129] \n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 209/209 [00:34<00:00,  6.02it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["121 2290 2008 93\n","0.5654205607476636 0.05683419445749178 0.1032863849765258 [2383 2129] \n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nYPVh1Eb0jQ0"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"5uBKJGB5Y_gM"},"source":["## Paragraph classification \n"]},{"cell_type":"code","metadata":{"id":"bF-BYjuaZDZ4"},"source":["import random\n","from tqdm import tqdm\n","from sklearn.metrics import confusion_matrix, accuracy_score, matthews_corrcoef\n","\n","def run_paragraph_classification_test3(distance = 1, distance2 =1):\n","    # total_images = 0\n","    paragraph_labels = []\n","    paragraph_predictions = []\n","\n","    sentence_labels = []\n","    sentence_predictions = []\n","    count = 0\n","    with tqdm(iter(test_articles), total=len(test_articles),leave=True) as t:\n","        for a_index, article in enumerate(t):\n","            for p_index, paragraph in enumerate([x for x in article['paragraphs'] if len(x)>2]):\n","                # random label\n","                count+=1\n","                label = count % 3 #random.randrange(2)\n","                if len(paragraph)>4 and random.randrange(3)!=0:\n","                    label=3\n","                # create sample accordingly\n","                sample = [s for s in paragraph]\n","                # print(len(sample))\n","                # gap_indexes = []\n","                if label==0:\n","                    pass\n","                else:\n","                    if language=='ROCStories':\n","                        if label==1 or label==3:\n","                            index = randrange(1,len(sample)-1)\n","                            sample.pop(index) \n","                            # gap_indexes.append(index-1)\n","                        if label==2 or label==3:\n","                            index = randrange(len(sample))\n","                            unrelated_sentence = get_random_sent_by_bm25(test_articles, sample[index])\n","                            sample[index] = unrelated_sentence\n","                            # unrelated_sentence_indexes.append(index)\n","                    elif language=='eng':\n","                        if label==3:\n","                            indexes = [x + i for i, x in enumerate(sorted(random.sample(range(1,5-(2)), 2)))]\n","                            sample.pop(indexes[0])\n","                            unrelated_sentence = get_random_sent_by_bm25(test_articles, sample[index])\n","                            sample[indexes[1]] = unrelated_sentence\n","                        if label==1:\n","                            numbers_of_unrelated = 1 \n","                            for i in range(numbers_of_unrelated):\n","                                index = randrange(1,len(sample)-1)\n","                                sample.pop(index)\n","                                # gap_indexes.append(index-1)\n","                        if label==2:\n","                            numbers_of_unrelated = 1 #min(randrange(1,3),len(sample)//2)\n","                            for i in range(numbers_of_unrelated):\n","                                index = randrange(len(sample))\n","                                unrelated_sentence = get_random_sent_by_bm25(test_articles, sample[index])\n","                                sample[index] = unrelated_sentence\n","                                # unrelated_sentence_indexes.append(index)\n","                    else:\n","                        if label==3:\n","                            indexes = [x + i for i, x in enumerate(sorted(random.sample(range(1,len(sample)-(2)), 2)))]\n","                            unrelated_sentence = get_random_sent(test_articles, a_index, p_index)\n","                            sample[indexes[0]] = unrelated_sentence\n","                            sample.pop(indexes[1])\n","                        if label==1:\n","                            numbers_of_unrelated = 1 \n","                            for i in range(numbers_of_unrelated):\n","                                index = randrange(1,len(sample)-1)\n","                                sample.pop(index)\n","                                # gap_indexes.append(index-1)\n","                        if label==2:\n","                            numbers_of_unrelated = 1 #min(randrange(1,3),len(sample)//2)\n","                            for i in range(numbers_of_unrelated):\n","                                index = randrange(len(sample))\n","                                unrelated_sentence = get_random_sent(test_articles, a_index, p_index)\n","                                sample[index] = unrelated_sentence\n","                                # unrelated_sentence_indexes.append(index)\n","                # process_paragraph (f(sample) -> label, unrelated_sentence_indexes)\n","                connection_pred, _ = process_paragraph(model, sample, distance=distance, generate_full_matrix=False)\n","                connection_pred2, _, _ = process_paragraph2(model, sample, distance=distance2, generate_full_matrix=False)\n","\n","                # check inserted sentence indexes in case of negative samples (unrelated_pred, compare to unrelated_sentence_indexes)\n","                # if label==1 and label==connection_pred:\n","                # sentence_labels.extend([ 1 if i in gap_indexes else 0 for i in range(len(sample)-1)])\n","                # sentence_predictions.extend(missing_pred)\n","\n","                # print([ 1 if i in gap_indexes else 0 for i in range(len(sample)-1)])\n","                # check label\n","                paragraph_labels.append(label)\n","                paragraph_predictions.append(connection_pred*2 + connection_pred2)\n","                # print(\" \")\n","                \n","    cm = confusion_matrix(paragraph_labels, paragraph_predictions, labels=[0,1,2,3])\n","    # figure = plot_confusion_matrix(cm, class_names=[\"Not containing unrelated sentence\", \"Containing unrelated sentence\"], title=\"Accuracy: {:3f}\\nMc: {:3f}\".format(\n","    #     accuracy_score(paragraph_labels, paragraph_predictions), matthews_corrcoef(paragraph_labels, paragraph_predictions)))\n","    # cm_image = plot_to_image(figure)\n","\n","    print(cm)\n","    \n","    a,b,c,d = precision_recall_fscore_support(paragraph_labels, paragraph_predictions, labels=[0,1,2,3])\n","    print(a,b,c,d,\"\\n\")\n","\n","    # figure = plot_confusion_matrix(cm, \n","    #                             title=\"Sentence relation\", \n","    #                             y_label=\"First sentence\", \n","    #                             x_label=\"Second sentence\", \n","    #                             class_names=[\"ok\",\"discordant sentence\", \"missing sentence\", \"both\"], \n","    #                             normalize=False, \n","    #                             side_labels=True)\n","    # cm_image = plot_to_image(figure, close=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"arPkGUd3GNtv"},"source":["### Paragraph Classification Result"]},{"cell_type":"code","metadata":{"id":"JiMj5L_Mmjef","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613135018800,"user_tz":-180,"elapsed":1491332,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}},"outputId":"43961934-4134-42b6-9cf4-150ee78b56b4"},"source":["for i in range(2):\n","    for j in range(2):\n","        print(i,\"-----\",j)\n","        run_paragraph_classification_test3(i+1,j+1)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/209 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["0 ----- 0\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 209/209 [01:04<00:00,  3.23it/s]\n","  0%|          | 1/209 [00:00<00:32,  6.36it/s]"],"name":"stderr"},{"output_type":"stream","text":["[[374  28  12 156]\n"," [369  14 103  91]\n"," [ 25  11 150 415]\n"," [  8  16  48 309]]\n","[0.48195876 0.20289855 0.47923323 0.31822863] [0.65614035 0.02426343 0.24958403 0.81102362] [0.55572065 0.04334365 0.32822757 0.45710059] [570 577 601 381] \n","\n","0 ----- 1\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 209/209 [01:04<00:00,  3.22it/s]\n","  0%|          | 1/209 [00:00<00:31,  6.60it/s]"],"name":"stderr"},{"output_type":"stream","text":["[[396   3  82  81]\n"," [396   2 128  54]\n"," [ 23   2  81 472]\n"," [ 10   7  41 351]]\n","[0.48       0.14285714 0.2439759  0.36638831] [0.70462633 0.00344828 0.14013841 0.85819071] [0.57101658 0.00673401 0.17802198 0.51353328] [562 580 578 409] \n","\n","1 ----- 0\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 209/209 [01:05<00:00,  3.21it/s]\n","  0%|          | 1/209 [00:00<00:32,  6.36it/s]"],"name":"stderr"},{"output_type":"stream","text":["[[374 116  12  70]\n"," [378  49 103  57]\n"," [ 24  44 130 397]\n"," [  1  48  48 278]]\n","[0.48133848 0.19066148 0.44368601 0.34663342] [0.65384615 0.0834753  0.21848739 0.74133333] [0.5544848  0.11611374 0.29279279 0.47238743] [572 587 595 375] \n","\n","1 ----- 1\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 209/209 [01:05<00:00,  3.17it/s]"],"name":"stderr"},{"output_type":"stream","text":["[[483  11   4  74]\n"," [440   5  95  44]\n"," [ 46   3  63 471]\n"," [ 34  15  15 326]]\n","[0.48155533 0.14705882 0.3559322  0.35628415] [0.84440559 0.00856164 0.10806175 0.83589744] [0.61333333 0.01618123 0.16578947 0.49961686] [572 584 583 390] \n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"AxVo4_rPL1cL"},"source":["torch.save({\n","    'language':language ,\n","    'bert_model_name':bert_model_name,\n","    'model_state_dict': model.state_dict()\n","    }, checkpoint_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qx-V3nWpEety"},"source":["## Paragraph classification \n"]},{"cell_type":"code","metadata":{"id":"VcbGmmGhEet2"},"source":["import random\n","from tqdm import tqdm\n","from sklearn.metrics import confusion_matrix, accuracy_score, matthews_corrcoef\n","\n","def run_paragraph_classification_test4(distance = 1, type=1):\n","    # total_images = 0\n","    paragraph_labels = []\n","    paragraph_predictions = []\n","\n","    sentence_labels = []\n","    sentence_predictions = []\n","    count = 0\n","    with tqdm(iter(test_articles), total=len(test_articles),leave=True) as t:\n","        for a_index, article in enumerate(t):\n","            for p_index, paragraph in enumerate([x for x in article['paragraphs'] if len(x)>2]):\n","                # random label\n","                count+=1\n","                label = count % 2 #random.randrange(2)\n","                # create sample accordingly\n","                sample = [s for s in paragraph]\n","                # print(len(sample))\n","                # gap_indexes = []\n","                if label==0:\n","                    pass\n","                else:\n","                    if language=='ROCStories':\n","                        if type==0:\n","                            index = randrange(1,len(sample)-1)\n","                            sample.pop(index) \n","                            # gap_indexes.append(index-1)\n","                        if type==1:\n","                            index = randrange(len(sample))\n","                            unrelated_sentence = get_random_sent_by_bm25(test_articles, sample[index])\n","                            sample[index] = unrelated_sentence\n","                            # unrelated_sentence_indexes.append(index)\n","                    elif language=='eng':\n","                        if type==0:\n","                            numbers_of_unrelated = 1 \n","                            for i in range(numbers_of_unrelated):\n","                                index = randrange(1,len(sample)-1)\n","                                sample.pop(index)\n","                                # gap_indexes.append(index-1)\n","                        if type==1:\n","                            numbers_of_unrelated = 1 #min(randrange(1,3),len(sample)//2)\n","                            for i in range(numbers_of_unrelated):\n","                                index = randrange(len(sample))\n","                                unrelated_sentence = get_random_sent_by_bm25(test_articles, sample[index])\n","                                sample[index] = unrelated_sentence\n","                                # unrelated_sentence_indexes.append(index)\n","                    else:\n","                        if type==0:\n","                            numbers_of_unrelated = 1 \n","                            for i in range(numbers_of_unrelated):\n","                                index = randrange(1,len(sample)-1)\n","                                sample.pop(index)\n","                                # gap_indexes.append(index-1)\n","                        if type==1:\n","                            numbers_of_unrelated = 1 #min(randrange(1,3),len(sample)//2)\n","                            for i in range(numbers_of_unrelated):\n","                                index = randrange(len(sample))\n","                                unrelated_sentence = get_random_sent(test_articles, a_index, p_index)\n","                                sample[index] = unrelated_sentence\n","                                # unrelated_sentence_indexes.append(index)\n","                # process_paragraph (f(sample) -> label, unrelated_sentence_indexes)\n","                if type==0:\n","                    connection_pred, _ = process_paragraph(model, sample, distance=distance, generate_full_matrix=False)\n","                if type==1:\n","                    connection_pred, _, _ = process_paragraph2(model, sample, distance=distance, generate_full_matrix=False)\n","\n","                # check inserted sentence indexes in case of negative samples (unrelated_pred, compare to unrelated_sentence_indexes)\n","                # if label==1 and label==connection_pred:\n","                # sentence_labels.extend([ 1 if i in gap_indexes else 0 for i in range(len(sample)-1)])\n","                # sentence_predictions.extend(missing_pred)\n","\n","                # print([ 1 if i in gap_indexes else 0 for i in range(len(sample)-1)])\n","                # check label\n","                paragraph_labels.append(label)\n","                paragraph_predictions.append(connection_pred)\n","                # print(\" \")\n","                \n","    cm = confusion_matrix(paragraph_labels, paragraph_predictions, labels=[0,1])\n","    # figure = plot_confusion_matrix(cm, class_names=[\"Not containing unrelated sentence\", \"Containing unrelated sentence\"], title=\"Accuracy: {:3f}\\nMc: {:3f}\".format(\n","    #     accuracy_score(paragraph_labels, paragraph_predictions), matthews_corrcoef(paragraph_labels, paragraph_predictions)))\n","    # cm_image = plot_to_image(figure)\n","\n","    print(cm)\n","    \n","    a,b,c,d = precision_recall_fscore_support(paragraph_labels, paragraph_predictions, labels=[0,1])\n","    print(a,b,c,d,\"\\n\")\n","\n","    # figure = plot_confusion_matrix(cm, \n","    #                             title=\"Sentence relation\", \n","    #                             y_label=\"First sentence\", \n","    #                             x_label=\"Second sentence\", \n","    #                             class_names=[\"ok\",\"discordant sentence\", \"missing sentence\", \"both\"], \n","    #                             normalize=False, \n","    #                             side_labels=True)\n","    # cm_image = plot_to_image(figure, close=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uG2BOyMBEet2"},"source":["### Paragraph Classification Result"]},{"cell_type":"code","metadata":{"id":"QiZ-WlAVEet2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613135161746,"user_tz":-180,"elapsed":1634270,"user":{"displayName":"Quang Huy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSYq4HGBBR4RWhBRRq-evALuMp-KdosblZGVMJelY=s64","userId":"06193573590509910395"}},"outputId":"eb18476a-4c80-49be-e645-40fca6a20806"},"source":["for i in range(2):\n","    for j in range(2):\n","        print(i,j)\n","        run_paragraph_classification_test4(distance=j+1,type=i)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/209 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["0 0\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 209/209 [00:33<00:00,  6.26it/s]\n","  0%|          | 0/209 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[[770 294]\n"," [715 350]]\n","[0.51851852 0.54347826] [0.72368421 0.3286385 ] [0.60415849 0.40959626] [1064 1065] \n","\n","0 1\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 209/209 [00:33<00:00,  6.29it/s]\n","  0%|          | 0/209 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[[927 137]\n"," [812 253]]\n","[0.53306498 0.64871795] [0.8712406  0.23755869] [0.66143418 0.34776632] [1064 1065] \n","\n","1 0\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 209/209 [00:32<00:00,  6.50it/s]\n","  0%|          | 0/209 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[[685 379]\n"," [252 813]]\n","[0.73105656 0.68204698] [0.64379699 0.76338028] [0.68465767 0.72042534] [1064 1065] \n","\n","1 1\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 209/209 [00:33<00:00,  6.22it/s]"],"name":"stderr"},{"output_type":"stream","text":["[[906 158]\n"," [199 866]]\n","[0.8199095  0.84570312] [0.85150376 0.81314554] [0.83540802 0.82910483] [1064 1065] \n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"buhkkZRGTsLp"},"source":["## Close Tensorboard Writers"]},{"cell_type":"code","metadata":{"id":"-q3XLUQ1Tms2"},"source":["# tb.close()\n","# tb_test.close()\n","# tb_training.close()\n","# tb_validation.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oOxRhVQ_H4W3"},"source":["# Tensorboard Summary"]},{"cell_type":"code","metadata":{"id":"m3ZhNp85VhWq"},"source":["# %load_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jIK8a_iCUKf2"},"source":["**1. Run the next block to get experiment' reports list.**"]},{"cell_type":"code","metadata":{"id":"mPXPlTbnOS5u"},"source":["#@title Available save files\n","# import os\n","# from os.path import join\n","\n","# for p in [ f.path for f in os.scandir(join(log_path_base)) if f.is_dir() ]:\n","#     print(\"\\\"\"+p+\"\\\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TmYLbyTzUk2N"},"source":["**2. Copy 1 of those and paste in examining_path and run it.**"]},{"cell_type":"code","metadata":{"id":"eNsDHjqeNYxi"},"source":["# import ipywidgets as widgets\n","# examining_path = \"\\\"/content/drive/My Drive/Colab Notebooks/next_sentence/logs/log_ROCStories_bert-base-uncased_pooler_0_768\\\"\" #@param {type:\"string\"}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pi73lU6aUlP3"},"source":["**3. Launch tensorboard**"]},{"cell_type":"code","metadata":{"id":"WThtxCRCCtGJ"},"source":["# %tensorboard --logdir {examining_path} --samples_per_plugin \"text=100,images=200\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dG8OMcj4wodO"},"source":["# Interactive form\n"]},{"cell_type":"markdown","metadata":{"id":"-Pq_P5S_4WB-"},"source":["Notes: require running 3 first main item + ((prepare dataset + create model and training) or (load model from checkpoint))"]},{"cell_type":"code","metadata":{"id":"liAIh2JuwsfB"},"source":["# #@title form \n","\n","# input = \"There are commonly two approaches when evaluating a \\\n","# keyphrase extraction model. The first approach involves a human \\\n","# annotator, who reads the article and the result extracted by the \\\n","# model and assesses them manually. \\\n","# Thus, the result of this paper can serve as a valuable resource to improve existing systems. \\\n","# This approach requires a high \\\n","# amount of manual effort, and the result can be affected by subjective \\\n","# opinions. The second approach makes use of the metrics like \\\n","# Precision, Recall, and F1-score and compares the extracted \\\n","# list of keyphrases with the list of keyphrases annotated by \\\n","# authors.\" \n","\n","# distance = 1 #@param {type:\"slider\", min:1, max:5, step:1}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fzlCXShbw-CK"},"source":["# import numpy \n","# # preprocessing input\n","# paragraph = [s.strip() for s in input.split('.') if s.strip()]\n","# # process with model\n","# matrix = create_paragraph_matrix(model, paragraph)\n","# # output result (sentence relation matrix, paragraph integrity prediction (+unrelated sentence prediction in negative case))\n","# figure = plot_confusion_matrix(matrix, \n","#                             title=\"Sentence relation\", \n","#                             y_label=\"First sentence\", \n","#                             x_label=\"Second sentence\", \n","#                             class_names=paragraph, \n","#                             normalize=False, \n","#                             side_labels=True)\n","# cm_image = plot_to_image(figure, close=False)\n","\n","# masked_matrix, _ = mask_paragraph_matrix(matrix, 2)\n","# figure = plot_confusion_matrix(numpy.array(masked_matrix), \n","#                             title=\"Sentence relation\", \n","#                             y_label=\"First sentence\", \n","#                             x_label=\"Second sentence\", \n","#                             class_names=paragraph, \n","#                             normalize=False, \n","#                             side_labels=True)\n","# cm_image = plot_to_image(figure, close=False)\n","\n","# integrity, unrelated = process_paragraph(model, paragraph, distance, cmatrix=matrix)\n","\n","# print(\"Paragraph integrity: {}; Unrelated sentences: {}\".format(str(integrity), str(unrelated)))\n"],"execution_count":null,"outputs":[]}]}